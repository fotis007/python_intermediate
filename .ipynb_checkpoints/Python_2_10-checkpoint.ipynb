{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Natural-Language-Processing-mit-Python\" data-toc-modified-id=\"Natural-Language-Processing-mit-Python-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Natural Language Processing mit Python</a></div><div class=\"lev2 toc-item\"><a href=\"#Text-in-Sätze-zerlegen\" data-toc-modified-id=\"Text-in-Sätze-zerlegen-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Text in Sätze zerlegen</a></div><div class=\"lev3 toc-item\"><a href=\"#1.-Textblob:\" data-toc-modified-id=\"1.-Textblob:-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>1. Textblob:</a></div><div class=\"lev3 toc-item\"><a href=\"#2.-Spacy\" data-toc-modified-id=\"2.-Spacy-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>2. Spacy</a></div><div class=\"lev2 toc-item\"><a href=\"#Tokenisieren\" data-toc-modified-id=\"Tokenisieren-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Tokenisieren</a></div><div class=\"lev3 toc-item\"><a href=\"#Spacy\" data-toc-modified-id=\"Spacy-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Spacy</a></div><div class=\"lev2 toc-item\"><a href=\"#Part-of-Speech-Tagging\" data-toc-modified-id=\"Part-of-Speech-Tagging-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Part-of-Speech-Tagging</a></div><div class=\"lev2 toc-item\"><a href=\"#Named-Entity-Recognition\" data-toc-modified-id=\"Named-Entity-Recognition-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Named Entity Recognition</a></div><div class=\"lev2 toc-item\"><a href=\"#Literatur-/-Links\" data-toc-modified-id=\"Literatur-/-Links-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Literatur / Links</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den nächsten zwei Sitzungen geht es um NLP mit Python. Da hierbei auch die jeweiligen Konzepte aus der Linguistik eingeführt werden müssen, werden wir nur einige wenige Grundbegriffe ansprechen. \n",
    "\n",
    "Sie werden dabei lernen, wie man mit zwei Bibliotheken diese Aufgaben erledigt, um dann in den Hausaufgaben mit weiteren Bibliotheken zu arbeiten. \n",
    "\n",
    "1. Textblob\n",
    "2. Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Als der Abend herbeikam und die Freunde in einer weitumherschauenden Laube saßen, trat eine ansehnliche Figur auf die Schwelle, welche unser Freund sogleich für den Barbier von heute früh erkannte. Auf einen tiefen, stummen Bückling des Mannes erwiderte Lenardo: Ihr kommt, wie immer, sehr gelegen und werdet nicht säumen, uns mit Eurem Talent zu erfreuen. — Ich kann Ihnen wohl, fuhr er zu Wilhelmen gewendet fort, Einiges von der Gesellschaft erzählen, deren Band zu sein ich mich rühmen darf. Niemand tritt in unsern Kreis, als wer gewisse Talente aufzuweisen hat, die zum Nutzen oder Vergnügen einer jeden Gesellschaft dienen würden. Dieser Mann ist ein derber Wundarzt, der in bedenklichen Fällen, wo Entschluß und körperliche Kraft gefordert wird, seinem Meister trefflich an der Seite zu stehen bereit ist. Was er als Bartkünstler leistet, davon können Sie ihm selbst ein Zeugniß geben. Hiedurch ist er uns eben so nöthig als willkommen. Da nun aber diese Beschäftigung gewöhnlich eine große und oft lästige Geschwätzigkeit mit sich führt, so hat er sich zu eigner Bildung eine Bedingung gefallen lassen, wie denn Jeder, der unter uns leben will, sich von einer gewissen Seite bedingen muß, wenn ihm nach anderen Seiten hin die größere Freiheit gewährt ist. Dieser also hat nun auf die Sprache Verzicht gethan, insofern etwas Gewöhnliches oder Zufälliges durch sie ausgedrückt wird; daraus aber hat sich ihm ein anderes Redetalent entwickelt, welches absichtlich, klug und erfreulich wirkt, die Gabe des Erzählens nämlich. Sein Leben ist reich an wunderlichen Erfahrungen, die er sonst zu ungelegener Zeit schwätzend zersplitterte, nun aber durch Schweigen genöthigt im stillen Sinne wiederholt und ordnet. Hiermit verbindet sich denn die Einbildungskraft und verleiht dem Geschehenen Leben und Bewegung. Mit besonderer Kunst und Geschicklichkeit weiß er wahrhafte Märchen und märchenhafte Geschichten zu erzählen, wodurch er oft zur schicklichen Stunde uns gar sehr ergötzt, wenn ihm die Zunge durch mich gelös't wird; wie ich denn gegenwärtig thue, und ihm zugleich das Lob ertheile, daß er sich in geraumer Zeit, seitdem ich ihn kenne, noch niemals wiederholt hat. Nun hoff' ich, daß er auch diesmal, unserm theuren Gast zu Lieb' und Ehren, sich besonders hervorthun werde.\n",
    "Ueber das Gesicht des Rothmantels verbreitete sich eine geistreiche Heiterkeit, und er fing ungesäumt folgendermaßen zu sprechen an:\n",
    "Hochverehrte Herren! da mir bekannt ist, daß Sie vorläufige Reden und Einleitungen nicht besonders lieben, so will ich ohne weiteres versichern, daß ich diesmal vorzüglich gut zu bestehen hoffe. Von mir sind zwar schon gar manche wahrhafte Geschichten zu hoher und allseitiger Zufriedenheit ausgegangen, heute aber darf ich sagen, daß ich eine zu erzählen habe, welche die bisherigen weit übertrifft, und die, wiewohl sie mir schon vor einigen Jahren begegnet ist, mich noch immer in der Erinnerung unruhig macht, ja sogar eine endliche Entwicklung hoffen läßt. Sie möchte schwerlich ihres Gleichen finden.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textblob installieren:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text in Sätze zerlegen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Textblob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  17\n",
      "Length of sentences in characters: \n",
      "197 - 158 - 138 - 141 - 175 - 79 - 50 - 319 - 264 - 183 - 97 - 362 - 108 - 153 - 173 - 366 - 44 - "
     ]
    }
   ],
   "source": [
    "from textblob_de import TextBlobDE as TextBlob\n",
    "from textblob_de import PatternParser\n",
    "\n",
    "doc = TextBlob(text)\n",
    "print(\"Number of sentences: \", len(doc.sentences))\n",
    "print(\"Length of sentences in characters: \")\n",
    "for s in doc.sentences:\n",
    "    print(len(s), end=\" - \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achtung: Mit doc.sentences iterieren wir über die Sätze im Text. Aber der Satz ist kein String, sondern ein besonderes Objekt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob_de.blob.Sentence"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-34440789d4f3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-34440789d4f3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Das gilt auch schon für unser Dokument-Objekt doc:\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Das gilt auch schon für unser Dokument-Objekt doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob_de.blob.TextBlobDE"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Gute daran, ist, dass wir  - wie oben - über dieses Objekt iterieren können:\n",
    "\n",
    "```\n",
    "for s in doc.sentences\n",
    "```\n",
    "\n",
    "Aber genau genommen iterieren wir ja nicht über das 'doc'-Objekt, sondern über die Daten einer bestimmten Sicht, die wir mit dem Attribut 'sentences' aktivieren. \n",
    "Wir können auch  andere Sichten aktivieren, z.B. Worte: \n",
    "```\n",
    "for w in doc.words\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Als', 'der', 'Abend', 'herbeikam', 'und', 'die', 'Freunde', 'in', 'einer', 'weitumherschauenden', 'Laube', 'saßen', 'trat', 'eine', 'ansehnliche', 'Figur', 'auf', 'die', 'Schwelle', 'welche'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = doc.words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob_de.blob.Word"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vielleicht sollten wir erst einmal erläutern, warum es nicht ganz einfach ist, einen Text in Sätze zu zerlegen. Zuuerst könnte man denken, dass man das mit einigen sehr einfachen Regeln erledigen kann, aber wie ein Blick auf das nächste Beispiel zeigt, ist das nicht so einfach:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_2 = \"\"\"Johann Wolfgang Goethe wurde, glaube ich, am 28.8.1749 geboren. Es könnte auch am 20.8. sein. Ich muss zugeben: Genau weiß ich das nicht.\"\"\"\n",
    "text_3 = \"\"\"Die heutige Agenda ist kurz. 1. Die Frage nach dem Anfang. 2. Ende. Viel Spaß!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Johann Wolfgang Goethe wurde, glaube ich, am 28.8.1749 geboren.\"),\n",
       " Sentence(\"Es könnte auch am 20.8. sein.\"),\n",
       " Sentence(\"Ich muss zugeben: Genau weiß ich das nicht.\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = TextBlob(text_2)\n",
    "list(doc.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Die heutige Agenda ist kurz.\"),\n",
       " Sentence(\"1.\"),\n",
       " Sentence(\"Die Frage nach dem Anfang.\"),\n",
       " Sentence(\"2.\"),\n",
       " Sentence(\"Ende.\"),\n",
       " Sentence(\"Viel Spaß!\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = TextBlob(text_3)\n",
    "list(doc.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA   \n",
      "                                                             \n",
      "           Das   DT     -       -      -      -      das     \n",
      "           ist   VB     VP      -      -      -      sein    \n",
      "           ein   DT     NP      -      -      -      ein     \n",
      "       schönes   JJ     NP ^    -      -      -      schön   \n",
      "          Auto   NN     NP ^    -      -      -      auto    \n",
      "             .   .      -       -      -      -      .       \n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Das ist ein schönes Auto.\", parser=PatternParser(pprint=True, lemmata=True))\n",
    "blob.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Die', 'heutige', 'Agenda', 'ist', 'kurz'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0].words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johann Wolfgang Goethe wurde, glaube ich, am 28.8.1749 geboren.\n",
      "Es könnte auch am 20.8. sein.\n",
      "Ich muss zugeben:\n",
      "Genau weiß ich das nicht.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('de')\n",
    "doc = nlp(text_2)\n",
    "for s in doc.sents:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die heutige Agenda ist kurz.\n",
      "1\n",
      ". Die Frage nach dem Anfang.\n",
      "2. Ende.\n",
      "Viel Spaß!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text_3)\n",
    "for s in doc.sents:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden werden wir nur mit Spacy weiterarbeiten. Für Spacy spricht, dass es recht neu ist, eine ganze Reihe von Sprachen unterstützt, ein modernes Python-Interface mit einer wohlüberlegten API hat, vergleichsweise neue Aspekte der Sprachtechnologie, z.B. Word Embeddings, unterstützt und dass Deutsch zu den gut unterstützten Sprachen zählt. Gegen Spacy spricht, dass es von einer privaten Firma entwickelt wird, allerdings wird das dadurch gemildert, dass spacy selbst auf github unter einer sehr freizügigen MIT-Lizenz verfügbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.11\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johann< | >Wolfgang< | >Goethe< | >wurde< | >,< | >glaube< | >ich< | >,< | >am< | >28.8.1749< | >geboren< | >.< | >Es< | >könnte< | >auch< | >am< | >20.8< | >.< | >sein< | >.< | >Ich< | >muss< | >zugeben< | >:< | >Genau< | >weiß< | >ich< | >das< | >nicht< | >.< | >"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "doc = nlp(text_2)\n",
    "for token in doc: \n",
    "    print(token.text, end=\"< | >\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die< | >heutige< | >Agenda< | >ist< | >kurz< | >.< | >1< | >.< | >Die< | >Frage< | >nach< | >dem< | >Anfang< | >.< | >2< | >.< | >Ende< | >.< | >Viel< | >Spaß< | >!< | >"
     ]
    }
   ],
   "source": [
    "doc = nlp(text_3)\n",
    "a = [print(token.text, end=\"< | >\") for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN          LEMMA          POS-Tag        \n",
      "Johann         Johann         PROPN          \n",
      "Wolfgang       Wolfgang       PROPN          \n",
      "Goethe         Goethe         PROPN          \n",
      "wurde          werden         AUX            \n",
      ",              ,              PUNCT          \n",
      "glaube         glauben        VERB           \n",
      "ich            ich            PRON           \n",
      ",              ,              PUNCT          \n",
      "am             am             ADP            \n",
      "28.8.1749      28.8.1749      NOUN           \n",
      "geboren        gebären        VERB           \n",
      ".              .              PUNCT          \n",
      "Es             Es             PRON           \n",
      "könnte         können         VERB           \n",
      "auch           auch           ADV            \n",
      "am             am             ADP            \n",
      "20.8           20.8           NOUN           \n",
      ".              .              PUNCT          \n",
      "sein           mein           AUX            \n",
      ".              .              PUNCT          \n",
      "Ich            Ich            PRON           \n",
      "muss           muss           ADJ            \n",
      "zugeben        zugeben        VERB           \n",
      ":              :              PUNCT          \n",
      "Genau          Genau          ADJ            \n",
      "weiß           weiß           VERB           \n",
      "ich            ich            PRON           \n",
      "das            der            PRON           \n",
      "nicht          nicht          PART           \n",
      ".              .              PUNCT          \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text_2)\n",
    "print(\"{:<15}{:<15}{:<15}\".format(\"TOKEN\", \"LEMMA\", \"POS-Tag\"))\n",
    "for token in doc:\n",
    "    print(\"{:15}{:15}{:15}\".format(token.text, token.lemma_, token.pos_ ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Diese', 'Auskunft', 'muss', 'ich', 'sich', 'nicht', 'geben', '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Diese Auskünfte muss ich dir nicht geben.\")\n",
    "[token.lemma_ for token in doc]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E007] 'spaCyIWNLP' already exists in pipeline. Existing names: ['tagger', 'parser', 'ner', 'spaCyIWNLP']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6bda69b5c935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy_iwnlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspaCyIWNLP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miwnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspaCyIWNLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmatizer_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'\\mydata\\Dropbox\\uni\\progrs\\spacy-iwnlp\\IWNLP.Lemmatizer_20170501.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miwnlp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Diese Auskünfte muss ich dir nicht geben.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\conda\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, component, name, before, after, first, last)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE007\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mafter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE006\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E007] 'spaCyIWNLP' already exists in pipeline. Existing names: ['tagger', 'parser', 'ner', 'spaCyIWNLP']"
     ]
    }
   ],
   "source": [
    "from spacy_iwnlp import spaCyIWNLP\n",
    "iwnlp = spaCyIWNLP(lemmatizer_path=r'\\mydata\\Dropbox\\uni\\progrs\\spacy-iwnlp\\IWNLP.Lemmatizer_20170501.json')\n",
    "nlp.add_pipe(iwnlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS: PRON\tIWNLP:None\n",
      "POS: VERB\tIWNLP:['mögen']\n",
      "POS: NOUN\tIWNLP:['Fußballspiel']\n",
      "POS: ADP\tIWNLP:None\n",
      "POS: ADJ\tIWNLP:['ausgedehnt']\n",
      "POS: NOUN\tIWNLP:['Verlängerung']\n",
      "POS: PUNCT\tIWNLP:None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, ['Auskunft'], ['müssen'], None, None, None, ['geben'], None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_iwnlp import spaCyIWNLP\n",
    "nlp = spacy.load('de')\n",
    "iwnlp = spaCyIWNLP(lemmatizer_path=r'\\mydata\\Dropbox\\uni\\progrs\\spacy-iwnlp\\IWNLP.Lemmatizer_20170501.json')\n",
    "nlp.add_pipe(iwnlp)\n",
    "doc = nlp('Wir mögen Fußballspiele mit ausgedehnten Verlängerungen.')\n",
    "for token in doc:\n",
    "    print('POS: {}\\tIWNLP:{}'.format(token.pos_, token._.iwnlp_lemmas))    \n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS: PRON\tIWNLP:None\n",
      "POS: VERB\tIWNLP:['mögen']\n",
      "POS: NOUN\tIWNLP:['Fußballspiel']\n",
      "POS: ADP\tIWNLP:None\n",
      "POS: ADJ\tIWNLP:['ausgedehnt']\n",
      "POS: NOUN\tIWNLP:['Verlängerung']\n",
      "POS: PUNCT\tIWNLP:None\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Wir mögen Fußballspiele mit ausgedehnten Verlängerungen.')\n",
    "for token in doc:\n",
    "    print('POS: {}\\tIWNLP:{}'.format(token.pos_, token._.iwnlp_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\conda\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"2325\" height=\"749.5\" style=\"max-width: none; height: 749.5px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Anfang</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">war</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">das</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Wort,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">das</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">aber</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">bald</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">durch</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">blutige</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Taten</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">ersetzt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">wurde.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,614.5 C70,439.5 375.0,439.5 375.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,616.5 L62,604.5 78,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M70,614.5 C70,527.0 195.0,527.0 195.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M195.0,616.5 L203.0,604.5 187.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M595,614.5 C595,527.0 720.0,527.0 720.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,616.5 L587,604.5 603,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M420,614.5 C420,439.5 725.0,439.5 725.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M725.0,616.5 L733.0,604.5 717.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M945,614.5 C945,89.5 2145.0,89.5 2145.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,616.5 L937,604.5 953,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,177.0 1965.0,177.0 1965.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,616.5 L1112,604.5 1128,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1295,614.5 C1295,264.5 1960.0,264.5 1960.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,616.5 L1287,604.5 1303,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1470,614.5 C1470,352.0 1955.0,352.0 1955.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,616.5 L1462,604.5 1478,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1645,614.5 C1645,527.0 1770.0,527.0 1770.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,616.5 L1637,604.5 1653,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M1470,614.5 C1470,439.5 1775.0,439.5 1775.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1775.0,616.5 L1783.0,604.5 1767.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-10\" stroke-width=\"2px\" d=\"M1995,614.5 C1995,527.0 2120.0,527.0 2120.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-10\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,616.5 L1987,604.5 2003,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-11\" stroke-width=\"2px\" d=\"M770,614.5 C770,2.0 2150.0,2.0 2150.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-11\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">rc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,616.5 L2158.0,604.5 2142.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "text_4 = \"Am Anfang war das Wort, das aber bald durch blutige Taten ersetzt wurde.\"\n",
    "doc = nlp(text_4)\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech-Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johann Wolfang von Goethe 20 45 PER\n",
      "Mozart 105 111 PER\n",
      "\n",
      " 113 114 PER\n",
      "Zauberflöte 127 138 MISC\n",
      "Samsung 184 191 MISC\n",
      "Samsung Note4 207 220 MISC\n",
      "\n",
      " 237 238 MISC\n",
      "BMW 258 261 ORG\n",
      "Steve Jobs 273 283 PER\n",
      "\n",
      " 355 356 ORG\n",
      "den USA 359 366 LOC\n",
      "Shakespeare 390 401 PER\n",
      "Berlin 414 420 LOC\n",
      "\n",
      "1 Mio. 468 475 ORG\n"
     ]
    }
   ],
   "source": [
    "text_5 = \"\"\"Früher hat man über Johann Wolfang von Goethe gesprochen, weil er den 'Faust' geschrieben hat, oder über Mozart, \n",
    "weil der die Zauberflöte komponiert hat. Heute dagegen redet man über Samsung, weil das neue Samsung Note4 erschienen ist, \n",
    "oder über den neuen BMW. Gut, über Steve Jobs hat man noch so geredet, als wäre er ein neuer Mozart der Technologie. \n",
    "In den USA weiß man kaum noch wer Shakespeare ist, und in Berlin benimmt man sich schon so, also könnte man mit \n",
    "1 Mio. € einen Goethe kaufen.\"\"\"\n",
    "#text_5 = text_5.replace(\"\\n\", \"\") #new lines irritate the parser\n",
    "doc = nlp(text_5)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literatur / Links\n",
    "* [Textblob](http://textblob.readthedocs.io/en/dev/)\n",
    "* [Spacy]()\n",
    "* Improved German lemmatization in Spacy: [spacy-iwnlp](https://github.com/Liebeck/spacy-iwnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "195px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
